<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
	<meta name="generator" content="Hugo 0.125.0"><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>YA Logs</title>

<meta name="description" content="">
<meta name="author" content="">
<link rel="canonical" href="https://yugajmera.github.io/">
<link crossorigin="anonymous" href="https://yugajmera.github.io/assets/css/stylesheet.ab4ae6179ea15f8d40abe2eaf7686672c2efdd6c8ab9f32ba68b327655b638ab.css" integrity="sha256-q0rmF56hX41Aq&#43;Lq92hmcsLv3WyKufMrposydlW2OKs=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://yugajmera.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://yugajmera.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://yugajmera.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://yugajmera.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://yugajmera.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://yugajmera.github.io/index.xml">
<link rel="alternate" type="application/json" href="https://yugajmera.github.io/index.json">
<link rel="alternate" hreflang="en" href="https://yugajmera.github.io/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

  

<meta property="og:title" content="YA Logs" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://yugajmera.github.io/" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="YA Logs"/>
<meta name="twitter:description" content=""/>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Organization",
  "name": "YA Logs",
  "url": "https://yugajmera.github.io/",
  "description": "",
  "thumbnailUrl": "https://yugajmera.github.io/favicon.ico",
  "sameAs": [
      "mailto:yugajmera@gmail.com", "https://github.com/YugAjmera", "https://linkedin.com/in/yug-ajmera", "https://instagram.com/yug_ajmera"
  ]
}
</script>
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://yugajmera.github.io/" accesskey="h" title="YA Logs (Alt + H)">YA Logs</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://yugajmera.github.io/" title="Home">
                    <span class="active">Home</span>
                </a>
            </li>
            <li>
                <a href="https://yugajmera.github.io/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="https://yugajmera.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<article class="first-entry home-info">
    <header class="entry-header">
        <h1>üëã Welcome to YA Logs</h1>
    </header>
    <div class="entry-content">
        <p>Hi, Yug here! This is a place where I document my learning notes.</p>
<p>¬†</p>
<p>I&rsquo;m currently a research engineer at NEC Labs America, working on challenging problems in autonomous driving. After work, you can find me at the gym üí™, cooking something at home üç≤, or catching sunsets ‚õÖ around the beautiful Bay Area!</p>

    </div>
    <footer class="entry-footer">
        <div class="social-icons" >
    <a href="mailto:yugajmera@gmail.com" target="_blank" rel="noopener noreferrer me"
        title="Email">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 21" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path>
    <polyline points="22,6 12,13 2,6"></polyline>
</svg>
    </a>
    <a href="https://github.com/YugAjmera" target="_blank" rel="noopener noreferrer me"
        title="Github">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22">
    </path>
</svg>
    </a>
    <a href="https://linkedin.com/in/yug-ajmera" target="_blank" rel="noopener noreferrer me"
        title="Linkedin">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path>
    <rect x="2" y="9" width="4" height="12"></rect>
    <circle cx="4" cy="4" r="2"></circle>
</svg>
    </a>
    <a href="https://instagram.com/yug_ajmera" target="_blank" rel="noopener noreferrer me"
        title="Instagram">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <rect x="2" y="2" width="20" height="20" rx="5" ry="5"></rect>
    <path d="M16 11.37A4 4 0 1 1 12.63 8 4 4 0 0 1 16 11.37z"></path>
    <line x1="17.5" y1="6.5" x2="17.5" y2="6.5"></line>
</svg>
    </a>
</div>

    </footer>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Understanding Neural Radiance Fields (NeRFs)
    </h2>
  </header>
  <div class="entry-content">
    <p>Imagine being able to generate photorealistic 3D models of objects and scenes that can be viewed from any angle, with details so realistic that they are indistinguishable from reality. That‚Äôs what the Neural Radiance Fields (NeRF) is capable of doing and much more. With more than 50 papers related to NeRFs in the CVPR 2022, it is one of the most influential papers of all time.
Neural fields A neural field is a neural network that parametrizes a signal....</p>
  </div>
  <footer class="entry-footer"><span title='2023-03-05 00:00:00 +0000 UTC'>March 5, 2023</span>&nbsp;¬∑&nbsp;8 min</footer>
  <a class="entry-link" aria-label="post link to Understanding Neural Radiance Fields (NeRFs)" href="https://yugajmera.github.io/posts/nerf/post/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Decoding Diffusion Models
    </h2>
  </header>
  <div class="entry-content">
    <p>Diffusion models are a new class of state-of-the-art generative models that generate diverse high-resolution images. There are already a bunch of different diffusion models that include Open AI‚Äôs DALL-E 2 and GLIDE, Google‚Äôs Imagen, and Stability AI‚Äôs Stable Diffusion. In this blog post, we will dig our way up from the basic principles described in the most prominent one, which is the Denoising Diffusion Probabilistic Models (DDPM) as initialized by Sohl-Dickstein et al in 2015 and then improved by Ho....</p>
  </div>
  <footer class="entry-footer"><span title='2022-11-20 00:00:00 +0000 UTC'>November 20, 2022</span>&nbsp;¬∑&nbsp;13 min</footer>
  <a class="entry-link" aria-label="post link to Decoding Diffusion Models" href="https://yugajmera.github.io/posts/diffusion-models/post/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Generative Adversarial Networks: A Two-player game
    </h2>
  </header>
  <div class="entry-content">
    <p>Introduced in 2014 by Goodfellow. et al, Generative Adversarial Networks (GANs) revolutionized the field of Generative modeling. They proposed a new framework that generated very realistic synthetic data trained through a minimax two-player game.
With GANs, we don‚Äôt explicitly learn the distribution of the data $p_{\text{data}}$, but we can still sample from it. Like VAEs, GANs also have two networks: a Generator and a Discriminator that are trained simultaneously.
A latent variable is sampled from a prior $\mathbf{z} \sim p(\mathbf{z})$ and passed through the Generator to obtain a fake sample $\mathbf{x} = G(\mathbf{z})$....</p>
  </div>
  <footer class="entry-footer"><span title='2022-11-19 00:00:00 +0000 UTC'>November 19, 2022</span>&nbsp;¬∑&nbsp;5 min</footer>
  <a class="entry-link" aria-label="post link to Generative Adversarial Networks: A Two-player game" href="https://yugajmera.github.io/posts/gan/post/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Generative Modeling with Variational Autoencoders
    </h2>
  </header>
  <div class="entry-content">
    <p>Till now, I have talked about supervised learning where our model is trained to learn a mapping function of data $\mathbf{x}$ to predict labels $\mathbf{y}$, for example, the tasks of classification, object detection, segmentation, image captioning, etc. However, supervised learning requires large datasets that are created with human annotations to train the models.
The other side of machine learning is called unsupervised learning where we just have data $\mathbf{x}$, and the goal is to learn some hidden underlying structure of the data using a model....</p>
  </div>
  <footer class="entry-footer"><span title='2022-11-18 00:00:00 +0000 UTC'>November 18, 2022</span>&nbsp;¬∑&nbsp;6 min</footer>
  <a class="entry-link" aria-label="post link to Generative Modeling with Variational Autoencoders" href="https://yugajmera.github.io/posts/variational-autoencoder/post/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">ResNet: The Revolution of Depth
    </h2>
  </header>
  <div class="entry-content">
    <p>In 2015, Batch Normalization was discovered, which heralded the progress of architectures as it was now possible to train deep networks without using any tricks - allowing us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, eliminating the need for Dropout.
Another major problem with deep networks was of vanishing/exploding gradients, but it was now being handled by Kaiming Initialization. With the stage set in place, experiments began on training deeper models....</p>
  </div>
  <footer class="entry-footer"><span title='2022-11-13 00:00:00 +0000 UTC'>November 13, 2022</span>&nbsp;¬∑&nbsp;4 min</footer>
  <a class="entry-link" aria-label="post link to ResNet: The Revolution of Depth" href="https://yugajmera.github.io/posts/resnet/post/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">InceptionNet: Google&#39;s comeback for ImageNet Challenge
    </h2>
  </header>
  <div class="entry-content">
    <p>The 2014 winner of the ImageNet challenge was the InceptionNet or GoogLeNet architecture from Google. The most straightforward way of improving the performance of deep neural networks is by increasing their size: depth (the number of layers) and width (the number of units at each layer).
But with such a big network comes a large number of parameters (which makes it prone to overfitting) and increased use of computation resources....</p>
  </div>
  <footer class="entry-footer"><span title='2022-11-12 00:00:00 +0000 UTC'>November 12, 2022</span>&nbsp;¬∑&nbsp;5 min</footer>
  <a class="entry-link" aria-label="post link to InceptionNet: Google&#39;s comeback for ImageNet Challenge" href="https://yugajmera.github.io/posts/inceptionnet/post/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">VGGNet: Very Deep Convolutional Networks
    </h2>
  </header>
  <div class="entry-content">
    <p>With the advent of AlexNet, all the submissions to the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) switched over to using convolutional neural networks. In 2013, the winner of this challenge was ZFNet, a modified version of AlexNet which gave better accuracy. It was also an 8-layer network that tweaked some of the layer configurations of AlexNet by trial and error.
ZFNet used 7 $\times$ 7 sized filters in the first layer with a stride of 2 instead of 11 $\times$ 11 filters with a stride of 4....</p>
  </div>
  <footer class="entry-footer"><span title='2022-10-18 00:00:00 +0000 UTC'>October 18, 2022</span>&nbsp;¬∑&nbsp;5 min</footer>
  <a class="entry-link" aria-label="post link to VGGNet: Very Deep Convolutional Networks" href="https://yugajmera.github.io/posts/vggnet/post/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">AlexNet: The First CNN to win ImageNet Challenge
    </h2>
  </header>
  <div class="entry-content">
    <p>Do you wonder about how to come up with different design choices (architecture, optimization method, data manipulation, loss function, etc.) for the deep learning model so that it gives the best performance? Let‚Äôs look at the different CNN architectures that have performed well in the past on image classification tasks.
The ImageNet Large Scale Visual Recognition Challenge (ILSVRC) was the huge benchmark for image classification because it held a yearly challenge from 2010 to 2017 where teams around the world would compete with their best-performing classification models....</p>
  </div>
  <footer class="entry-footer"><span title='2022-10-09 00:00:00 +0000 UTC'>October 9, 2022</span>&nbsp;¬∑&nbsp;6 min</footer>
  <a class="entry-link" aria-label="post link to AlexNet: The First CNN to win ImageNet Challenge" href="https://yugajmera.github.io/posts/alexnet/post/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Image Classification using CNNs: MNIST dataset
    </h2>
  </header>
  <div class="entry-content">
    <p>Image classification is a fundamental task in computer vision that attempts to comprehend an entire image as a whole. The goal is to classify the image by assigning it to a specific class label. Typically, image classification refers to images in which only one object appears and is analyzed.
Now that we have all the ingredients required to code up our deep learning architecture, let‚Äôs dive right into creating a model that can classify handwritten digits (MNIST Dataset) using Convolutional Neural Networks from scratch....</p>
  </div>
  <footer class="entry-footer"><span title='2022-09-19 00:00:00 +0000 UTC'>September 19, 2022</span>&nbsp;¬∑&nbsp;6 min</footer>
  <a class="entry-link" aria-label="post link to Image Classification using CNNs: MNIST dataset" href="https://yugajmera.github.io/posts/img-classification-mnist/post/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Neural Network for Images: Convolutional Neural Networks (CNNs)
    </h2>
  </header>
  <div class="entry-content">
    <p>Linear Neural Networks that we have talked about till this point do not work when dealing with image data, as they don‚Äôt respect the spatial structure of images. When a neural network is applied to a 2D image, it flattens it out in 1D and then uses it as input. This creates a need for a new computational node that operates on images - Convolutional Neural Networks (CNNs).
A convolution layer has a 3D image tensor (3 X H X W) as an input and a 3D filter (also called a kernel) that convolves over the image, i....</p>
  </div>
  <footer class="entry-footer"><span title='2022-09-18 00:00:00 +0000 UTC'>September 18, 2022</span>&nbsp;¬∑&nbsp;4 min</footer>
  <a class="entry-link" aria-label="post link to Neural Network for Images: Convolutional Neural Networks (CNNs)" href="https://yugajmera.github.io/posts/cnn/post/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="next" href="https://yugajmera.github.io/page/2/">Next&nbsp;&nbsp;¬ª
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://yugajmera.github.io/">YA Logs</a></span> ¬∑ 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
