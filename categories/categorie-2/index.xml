<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Categorie 2 on YA Logs</title>
    <link>http://localhost:1313/categories/categorie-2/</link>
    <description>Recent content in Categorie 2 on YA Logs</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 30 Jul 2022 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/categorie-2/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Loss functions</title>
      <link>http://localhost:1313/posts/loss-function/post/</link>
      <pubDate>Sat, 30 Jul 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/loss-function/post/</guid>
      <description>While there are a ton of concepts related to Deep learning scrambled all around the internet, I thought why not have just one place where you can find all the fundamental concepts required to write your own Deep Neural Network (DNN). But, if you have time and would prefer to watch a video over reading a blog, I would recommend -
In this first part, I will discuss one of the most essential elements of deep learning - the loss function!</description>
    </item>
  </channel>
</rss>
